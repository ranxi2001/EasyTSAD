import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from scipy.ndimage import gaussian_filter1d
from sklearn.ensemble import IsolationForest
from EasyTSAD.Controller import TSADController

if __name__ == "__main__":
    
    print("[LOG] å¼€å§‹è¿è¡ŒVotingEnsemble - ç»Ÿè®¡å­¦+æ·±åº¦å­¦ä¹ æŠ•ç¥¨èåˆå¼‚å¸¸æ£€æµ‹")
    
    # Create a global controller
    gctrl = TSADController()
    print("[LOG] TSADControllerå·²åˆ›å»º")
        
    """============= [DATASET SETTINGS] ============="""
    datasets = ["machine-1", "machine-2", "machine-3"]
    dataset_types = "MTS"
    
    print("[LOG] å¼€å§‹è®¾ç½®æ•°æ®é›†")
    gctrl.set_dataset(
        dataset_type="MTS",
        dirname="./datasets",
        datasets=datasets,
    )
    print("[LOG] æ•°æ®é›†è®¾ç½®å®Œæˆ")

    """============= VotingEnsembleæŠ•ç¥¨èåˆæ¨¡å‹ ============="""
    from EasyTSAD.Methods import BaseMethod
    from EasyTSAD.DataFactory import MTSData

    print("[LOG] å¼€å§‹å®šä¹‰VotingEnsembleç±»")
    
    class VotingEnsemble(BaseMethod):
        """
        VotingEnsemble: ç»Ÿè®¡å­¦+æ·±åº¦å­¦ä¹ æŠ•ç¥¨èåˆå¼‚å¸¸æ£€æµ‹
        
        æ ¸å¿ƒè®¾è®¡ç†å¿µ:
        1. ä¿æŒMTSExampleç»Ÿè®¡å­¦æ–¹æ³•çš„å¼ºåŠ²Point F1æ€§èƒ½ (93.66%)
        2. æ·»åŠ è½»é‡çº§æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸“é—¨ä¼˜åŒ–Eventè¿ç»­æ€§
        3. é€šè¿‡æ™ºèƒ½æŠ•ç¥¨æœºåˆ¶èåˆä¸¤è€…ä¼˜åŠ¿
        4. ä¸“é—¨é’ˆå¯¹Event F1è®¾è®¡æŠ•ç¥¨ç­–ç•¥
        
        è®¾è®¡ç›®æ ‡: Point F1ç»´æŒ93%+, Event F1æå‡åˆ°80%+
        æŠ•ç¥¨ç­–ç•¥: ç»Ÿè®¡å­¦ä¸»å¯¼Pointç²¾åº¦ï¼Œæ·±åº¦å­¦ä¹ å¢å¼ºEventè¿ç»­æ€§
        """
        
        def __init__(self, params: dict) -> None:
            super().__init__()
            self.__anomaly_score = None
            
            # æ ¸å¿ƒè¶…å‚æ•°
            self.window_size = 16  # è½»é‡çº§çª—å£
            self.input_dim = 38    # æœºå™¨æ•°æ®ç‰¹å¾ç»´åº¦
            self.hidden_dim = 32   # è½»é‡çº§éšè—ç»´åº¦
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # åˆå§‹åŒ–æ¨¡å‹ç»„ä»¶
            self._init_models()
            print("[LOG] VotingEnsemble.__init__() è°ƒç”¨ï¼ŒåŒè·¯å¾„æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        def _init_models(self):
            """åˆå§‹åŒ–ç»Ÿè®¡å­¦å’Œæ·±åº¦å­¦ä¹ åŒè·¯å¾„"""
            
            # 1. ç»Ÿè®¡å­¦æ£€æµ‹å™¨ (åŸºäºMTSExample)
            self.statistical_detector = StatisticalDetector()
            
            # 2. è½»é‡çº§æ·±åº¦å­¦ä¹ æ£€æµ‹å™¨ (ä¸“é—¨ä¼˜åŒ–Eventè¿ç»­æ€§)
            self.deep_detector = LightEventDetector(
                input_dim=self.input_dim,
                hidden_dim=self.hidden_dim,
                window_size=self.window_size
            ).to(self.device)
            
            # 3. æ™ºèƒ½æŠ•ç¥¨å™¨ (èåˆä¸¤ç§æ–¹æ³•)
            self.voting_system = IntelligentVotingSystem()
            
        def train_valid_phase(self, tsData):
            """è®­ç»ƒé˜¶æ®µ: åªè®­ç»ƒæ·±åº¦å­¦ä¹ ç»„ä»¶"""
            print(f"[LOG] VotingEnsemble.train_valid_phase() è°ƒç”¨ï¼Œæ•°æ®å½¢çŠ¶: {tsData.train.shape}")
            
            train_data = tsData.train
            
            # ç»Ÿè®¡å­¦æ–¹æ³•ä¸éœ€è¦è®­ç»ƒ
            print("[LOG] ç»Ÿè®¡å­¦æ£€æµ‹å™¨æ— éœ€è®­ç»ƒ")
            
            # è®­ç»ƒè½»é‡çº§æ·±åº¦å­¦ä¹ æ¨¡å‹
            print("[LOG] å¼€å§‹è®­ç»ƒè½»é‡çº§æ·±åº¦å­¦ä¹ æ£€æµ‹å™¨...")
            self._train_deep_detector(train_data)
            print("[LOG] æ·±åº¦å­¦ä¹ æ£€æµ‹å™¨è®­ç»ƒå®Œæˆ")
            
        def _train_deep_detector(self, train_data):
            """è®­ç»ƒè½»é‡çº§æ·±åº¦å­¦ä¹ æ£€æµ‹å™¨"""
            
            # åˆ›å»ºè®­ç»ƒçª—å£
            windows = self._create_windows(train_data)
            if len(windows) == 0:
                print("[LOG] è­¦å‘Š: è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè·³è¿‡æ·±åº¦å­¦ä¹ è®­ç»ƒ")
                return
                
            train_dataset = TensorDataset(torch.FloatTensor(windows))
            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
            
            # ä¼˜åŒ–å™¨è®¾ç½® (è½»é‡çº§è®­ç»ƒ)
            optimizer = optim.Adam(self.deep_detector.parameters(), lr=1e-3)
            
            # ç®€å•å¿«é€Ÿè®­ç»ƒ (10è½®å³å¯)
            self.deep_detector.train()
            for epoch in range(10):
                epoch_loss = 0
                for batch_idx, (batch_data,) in enumerate(train_loader):
                    batch_data = batch_data.to(self.device)
                    
                    # è‡ªç›‘ç£é‡æ„æŸå¤±
                    loss = self.deep_detector.compute_loss(batch_data)
                    
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                
                if epoch % 5 == 0:
                    avg_loss = epoch_loss / len(train_loader) if len(train_loader) > 0 else 0
                    print(f"[LOG] Deep Detector Epoch {epoch}, Loss: {avg_loss:.4f}")
            
            self.deep_detector.eval()
            
        def test_phase(self, tsData: MTSData):
            """æµ‹è¯•é˜¶æ®µ: åŒè·¯å¾„æ£€æµ‹ + æ™ºèƒ½æŠ•ç¥¨èåˆ"""
            print(f"[LOG] VotingEnsemble.test_phase() è°ƒç”¨ï¼Œæµ‹è¯•æ•°æ®å½¢çŠ¶: {tsData.test.shape}")
            
            test_data = tsData.test
            
            # === è·¯å¾„1: ç»Ÿè®¡å­¦æ£€æµ‹ (ä¿æŒMTSExampleä¼˜åŠ¿) ===
            print("[LOG] æ‰§è¡Œç»Ÿè®¡å­¦æ£€æµ‹...")
            stat_scores = self.statistical_detector.detect(test_data)
            
            # === è·¯å¾„2: æ·±åº¦å­¦ä¹ æ£€æµ‹ (ä¸“é—¨ä¼˜åŒ–Eventè¿ç»­æ€§) ===
            print("[LOG] æ‰§è¡Œæ·±åº¦å­¦ä¹ æ£€æµ‹...")
            deep_scores = self._deep_detect(test_data)
            
            # === è·¯å¾„3: æ™ºèƒ½æŠ•ç¥¨èåˆ ===
            print("[LOG] æ‰§è¡Œæ™ºèƒ½æŠ•ç¥¨èåˆ...")
            final_scores = self.voting_system.vote(
                statistical_scores=stat_scores,
                deep_scores=deep_scores,
                original_data=test_data
            )
            
            # æœ€ç»ˆå½’ä¸€åŒ–
            if len(final_scores) > 0:
                final_scores = (final_scores - np.min(final_scores)) / (np.max(final_scores) - np.min(final_scores) + 1e-10)
            
            self.__anomaly_score = final_scores
            print(f"[LOG] VotingEnsembleå¼‚å¸¸åˆ†æ•°è®¡ç®—å®Œæˆï¼Œé•¿åº¦: {len(final_scores)}")
            print(f"[LOG] åˆ†æ•°ç»Ÿè®¡: min={np.min(final_scores):.4f}, max={np.max(final_scores):.4f}, mean={np.mean(final_scores):.4f}")
            
        def _deep_detect(self, test_data):
            """æ·±åº¦å­¦ä¹ æ£€æµ‹"""
            windows = self._create_sliding_windows(test_data)
            
            if len(windows) == 0:
                # å¦‚æœæ— æ³•åˆ›å»ºçª—å£ï¼Œè¿”å›ç»Ÿè®¡å­¦åˆ†æ•°
                return np.zeros(len(test_data))
            
            self.deep_detector.eval()
            all_scores = []
            
            with torch.no_grad():
                for i in range(0, len(windows), 16):  # å°æ‰¹é‡å¤„ç†
                    batch = windows[i:i+16]
                    batch_tensor = torch.FloatTensor(batch).to(self.device)
                    
                    # æ·±åº¦å­¦ä¹ å¼‚å¸¸åˆ†æ•°
                    scores = self.deep_detector.predict(batch_tensor)
                    scores_numpy = scores.cpu().numpy()
                    
                    if scores_numpy.ndim == 0:
                        scores_numpy = np.array([scores_numpy])
                    
                    all_scores.extend(scores_numpy)
            
            # å¯¹é½åˆ°åŸå§‹é•¿åº¦
            aligned_scores = self._align_scores_to_original(all_scores, len(test_data))
            return aligned_scores
        
        def _create_windows(self, data):
            """åˆ›å»ºè®­ç»ƒçª—å£"""
            if len(data) < self.window_size:
                return np.array([])
            
            windows = []
            for i in range(0, len(data) - self.window_size + 1, self.window_size // 2):
                window = data[i:i + self.window_size]
                windows.append(window)
            return np.array(windows)
        
        def _create_sliding_windows(self, data):
            """åˆ›å»ºæ»‘åŠ¨çª—å£"""
            if len(data) < self.window_size:
                return np.array([])
                
            windows = []
            for i in range(len(data) - self.window_size + 1):
                window = data[i:i + self.window_size]
                windows.append(window)
            return np.array(windows)
        
        def _align_scores_to_original(self, scores, original_length):
            """å°†çª—å£åˆ†æ•°å¯¹é½åˆ°åŸå§‹æ—¶é—´åºåˆ—é•¿åº¦"""
            if len(scores) == 0:
                return np.zeros(original_length)
            
            aligned = np.zeros(original_length)
            count = np.zeros(original_length)
            
            for i, score in enumerate(scores):
                start_idx = i
                end_idx = min(i + self.window_size, original_length)
                aligned[start_idx:end_idx] += score
                count[start_idx:end_idx] += 1
            
            mask = count > 0
            aligned[mask] /= count[mask]
            
            return aligned
            
        def anomaly_score(self) -> np.ndarray:
            print(f"[LOG] VotingEnsemble.anomaly_score() è°ƒç”¨")
            return self.__anomaly_score
        
        def param_statistic(self, save_file):
            print(f"[LOG] VotingEnsemble.param_statistic() è°ƒç”¨ï¼Œä¿å­˜åˆ°: {save_file}")
            
            # è®¡ç®—æ·±åº¦å­¦ä¹ æ¨¡å‹å‚æ•°
            deep_params = sum(p.numel() for p in self.deep_detector.parameters())
            
            param_info = f"""
                VotingEnsembleç®—æ³•å‚æ•°ç»Ÿè®¡:

                ğŸ¯ è®¾è®¡ç›®æ ‡: ç»Ÿè®¡å­¦+æ·±åº¦å­¦ä¹ æŠ•ç¥¨èåˆå¼‚å¸¸æ£€æµ‹
                ğŸ“Š é¢„æœŸæ€§èƒ½: Point F1: 93%+ (ä¿æŒMTSExampleä¼˜åŠ¿), Event F1: 80%+ (æ·±åº¦å­¦ä¹ å¢å¼º)

                ğŸ—ï¸ åŒè·¯å¾„æ¶æ„:
                1. ç»Ÿè®¡å­¦æ£€æµ‹å™¨: MTSExampleçš„L2èŒƒæ•°æ–¹æ³• (0å‚æ•°)
                2. è½»é‡çº§æ·±åº¦å­¦ä¹ æ£€æµ‹å™¨: ä¸“é—¨ä¼˜åŒ–Eventè¿ç»­æ€§ (~{deep_params}å‚æ•°)
                3. æ™ºèƒ½æŠ•ç¥¨ç³»ç»Ÿ: è‡ªé€‚åº”èåˆä¸¤ç§æ–¹æ³•

                ğŸ”¢ å‚æ•°ç»Ÿè®¡:
                - ç»Ÿè®¡å­¦è·¯å¾„: 0ä¸ªå‚æ•° (çº¯è®¡ç®—)
                - æ·±åº¦å­¦ä¹ è·¯å¾„: ~{deep_params:,}ä¸ªå‚æ•°
                - æ€»å‚æ•°é‡: ~{deep_params:,}ä¸ª (ç›¸æ¯”EventMasterå¤§å¹…å‡å°‘)
                - çª—å£å¤§å°: {self.window_size} (è½»é‡çº§è®¾è®¡)

                ğŸ’¡ æ ¸å¿ƒåˆ›æ–°:
                1. åŒè·¯å¾„è®¾è®¡: ç»Ÿè®¡å­¦ä¿è¯Pointç²¾åº¦ï¼Œæ·±åº¦å­¦ä¹ ä¼˜åŒ–Eventè¿ç»­æ€§
                2. æ™ºèƒ½æŠ•ç¥¨: è‡ªé€‚åº”æƒé‡ï¼Œä»»åŠ¡å¯¼å‘èåˆ
                3. è½»é‡çº§è®­ç»ƒ: ä»…10è½®è®­ç»ƒï¼Œå¿«é€Ÿæ”¶æ•›
                4. ä¸“é—¨åå¤„ç†: é’ˆå¯¹Event F1ä¼˜åŒ–çš„è¿æ¥ç­–ç•¥

                ğŸš€ æŠ€æœ¯ä¼˜åŠ¿:
                - ä¿æŒMTSExampleçš„Point F1ä¼˜åŠ¿ (93%+)
                - é€šè¿‡æ·±åº¦å­¦ä¹ å¤§å¹…æå‡Event F1 (ç›®æ ‡80%+)
                - è½»é‡çº§è®¾è®¡ï¼Œè®­ç»ƒå’Œæ¨ç†éƒ½å¾ˆå¿«
                - å·¥ç¨‹å‹å¥½ï¼Œæ˜“äºéƒ¨ç½²å’Œè°ƒè¯•

                âš¡ æŠ•ç¥¨ç­–ç•¥:
                - Pointç²¾åº¦: ç»Ÿè®¡å­¦ä¸»å¯¼ (70%) + æ·±åº¦å­¦ä¹ è¾…åŠ© (30%)
                - Eventè¿ç»­æ€§: æ·±åº¦å­¦ä¹ ä¸»å¯¼ (60%) + ç»Ÿè®¡å­¦åŸºç¡€ (40%)
                - è‡ªé€‚åº”æƒé‡: æ ¹æ®æ•°æ®ç‰¹æ€§åŠ¨æ€è°ƒæ•´

                ğŸ¯ è®¾è®¡å“²å­¦:
                "å–é•¿è¡¥çŸ­ï¼ŒæŠ•ç¥¨å†³ç­–" - ç»Ÿè®¡å­¦çš„Pointç²¾åº¦ + æ·±åº¦å­¦ä¹ çš„Eventè¿ç»­æ€§
            """
            
            with open(save_file, 'w', encoding='utf-8') as f:
                f.write(param_info)


    # ================== ç»„ä»¶å®šä¹‰ ==================

    class StatisticalDetector:
        """ç»Ÿè®¡å­¦æ£€æµ‹å™¨: åŸºäºMTSExampleçš„æˆåŠŸæ–¹æ³•"""
        
        def detect(self, data):
            """MTSExampleçš„L2èŒƒæ•°æ–¹æ³•"""
            # å®Œå…¨å¤åˆ¶MTSExampleçš„æˆåŠŸé€»è¾‘
            scores = np.sum(np.square(data), axis=1)
            
            if len(scores) > 0:
                scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores) + 1e-10)
                
            return scores


    class LightEventDetector(nn.Module):
        """è½»é‡çº§æ·±åº¦å­¦ä¹ æ£€æµ‹å™¨: ä¸“é—¨ä¼˜åŒ–Eventè¿ç»­æ€§"""
        
        def __init__(self, input_dim, hidden_dim, window_size):
            super().__init__()
            self.input_dim = input_dim
            self.hidden_dim = hidden_dim
            self.window_size = window_size
            
            # æç®€æ¶æ„: åªæœ‰ä¸€ä¸ªLSTM + ä¸€ä¸ªå…¨è¿æ¥å±‚
            self.lstm = nn.LSTM(
                input_size=input_dim,
                hidden_size=hidden_dim,
                num_layers=1,
                batch_first=True
            )
            
            # å¼‚å¸¸åˆ†æ•°é¢„æµ‹å¤´
            self.score_head = nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim // 2),
                nn.ReLU(),
                nn.Linear(hidden_dim // 2, 1),
                nn.Sigmoid()
            )
            
        def forward(self, x):
            # x: [batch, seq_len, features]
            lstm_out, _ = self.lstm(x)
            # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
            last_output = lstm_out[:, -1, :]  # [batch, hidden_dim]
            score = self.score_head(last_output)  # [batch, 1]
            return score.squeeze(-1)  # [batch]
        
        def compute_loss(self, x):
            """è‡ªç›‘ç£é‡æ„æŸå¤±"""
            # ç®€å•çš„è‡ªç›‘ç£ä»»åŠ¡: é¢„æµ‹çª—å£å†…çš„å¼‚å¸¸ç¨‹åº¦
            # åŸºäºçª—å£å†…å˜å¼‚åº¦çš„å¤§å°
            batch_size, seq_len, features = x.size()
            
            # è®¡ç®—çœŸå®çš„å˜å¼‚åº¦ä½œä¸ºä¼ªæ ‡ç­¾
            window_var = torch.var(x.view(batch_size, -1), dim=1)  # [batch]
            window_var = (window_var - window_var.min()) / (window_var.max() - window_var.min() + 1e-8)
            
            # æ¨¡å‹é¢„æµ‹
            pred_score = self.forward(x)  # [batch]
            
            # MSEæŸå¤±
            loss = nn.MSELoss()(pred_score, window_var)
            return loss
        
        def predict(self, x):
            """é¢„æµ‹å¼‚å¸¸åˆ†æ•°"""
            return self.forward(x)


    class IntelligentVotingSystem:
        """æ™ºèƒ½æŠ•ç¥¨ç³»ç»Ÿ: è‡ªé€‚åº”èåˆç»Ÿè®¡å­¦å’Œæ·±åº¦å­¦ä¹ """
        
        def __init__(self):
            self.isolation_forest = None
            
        def vote(self, statistical_scores, deep_scores, original_data):
            """æ™ºèƒ½æŠ•ç¥¨èåˆ"""
            
            # === ç¬¬1æ­¥: åŸºç¡€èåˆ ===
            # Pointç²¾åº¦å¯¼å‘: ç»Ÿè®¡å­¦ä¸»å¯¼
            point_focused = 0.7 * statistical_scores + 0.3 * deep_scores
            
            # Eventè¿ç»­æ€§å¯¼å‘: æ·±åº¦å­¦ä¹ ä¸»å¯¼  
            event_focused = 0.4 * statistical_scores + 0.6 * deep_scores
            
            # === ç¬¬2æ­¥: Eventè¿ç»­æ€§å¢å¼º ===
            # å¯¹Eventå¯¼å‘çš„åˆ†æ•°è¿›è¡Œå¹³æ»‘å¤„ç†
            event_smoothed = gaussian_filter1d(event_focused, sigma=2.0)
            
            # === ç¬¬3æ­¥: Isolation Forestå¢å¼º ===
            if self.isolation_forest is None:
                self.isolation_forest = IsolationForest(
                    contamination=0.1,
                    random_state=42,
                    n_estimators=30  # è½»é‡çº§è®¾ç½®
                )
                self.isolation_forest.fit(original_data)
            
            if_scores = self.isolation_forest.decision_function(original_data)
            if_scores = (if_scores - np.min(if_scores)) / (np.max(if_scores) - np.min(if_scores) + 1e-10)
            
            # === ç¬¬4æ­¥: è‡ªé€‚åº”æƒé‡èåˆ ===
            # è®¡ç®—ä¸¤ç§æ–¹æ³•çš„ä¸€è‡´æ€§
            consistency = self._compute_consistency(statistical_scores, deep_scores)
            
            # ä¸€è‡´æ€§é«˜æ—¶åå‘ç»Ÿè®¡å­¦ (ä¿è¯Pointç²¾åº¦)
            # ä¸€è‡´æ€§ä½æ—¶å¢åŠ æ·±åº¦å­¦ä¹ æƒé‡ (å¯èƒ½çš„æ–°å¼‚å¸¸)
            adaptive_weight = 0.6 + 0.2 * consistency  # [0.6, 0.8]
            
            # æœ€ç»ˆèåˆ
            final_scores = (
                adaptive_weight * point_focused +          # ä¿è¯Pointç²¾åº¦
                (1 - adaptive_weight) * event_smoothed +   # å¢å¼ºEventè¿ç»­æ€§  
                0.1 * if_scores                            # Isolation Forestå¢å¼º
            )
            
            # === ç¬¬5æ­¥: Eventè¿æ¥ä¼˜åŒ– ===
            connected_scores = self._connect_nearby_anomalies(final_scores)
            
            return connected_scores
        
        def _compute_consistency(self, scores1, scores2):
            """è®¡ç®—ä¸¤ç§æ–¹æ³•çš„ä¸€è‡´æ€§"""
            # è®¡ç®—åˆ†æ•°çš„ç›¸å…³ç³»æ•°
            correlation = np.corrcoef(scores1, scores2)[0, 1]
            if np.isnan(correlation):
                correlation = 0.0
            
            # è½¬æ¢åˆ°[0, 1]èŒƒå›´
            consistency = (correlation + 1) / 2
            return consistency
        
        def _connect_nearby_anomalies(self, scores, gap_threshold=2):
            """è¿æ¥ç›¸è¿‘çš„å¼‚å¸¸ç‚¹ï¼Œä¸“é—¨ä¼˜åŒ–Event F1"""
            threshold = np.percentile(scores, 85)
            anomaly_mask = scores > threshold
            
            # å¡«å……å°é—´éš™
            result_mask = anomaly_mask.copy()
            gap_count = 0
            
            for i in range(1, len(anomaly_mask) - 1):
                if not anomaly_mask[i]:
                    gap_count += 1
                else:
                    if gap_count > 0 and gap_count <= gap_threshold:
                        result_mask[i-gap_count:i] = True
                    gap_count = 0
            
            # åº”ç”¨è¿æ¥ç»“æœ
            connected_scores = scores.copy()
            connected_scores[result_mask] = np.maximum(
                connected_scores[result_mask],
                threshold * 0.9
            )
            
            return connected_scores


    print("[LOG] VotingEnsembleç±»å®šä¹‰å®Œæˆ")
    
    """============= Run VotingEnsemble ============="""
    training_schema = "mts"
    method = "VotingEnsemble"
    
    print(f"[LOG] å¼€å§‹è¿è¡Œå®éªŒï¼Œmethod={method}, training_schema={training_schema}")
    
    # run models
    gctrl.run_exps(
        method=method,
        training_schema=training_schema,
        preprocess="z-score",  # ç»§æ‰¿MTSExampleçš„æˆåŠŸç»éªŒ
    )
    print("[LOG] å®éªŒè¿è¡Œå®Œæˆ")
       
    """============= [EVALUATION SETTINGS] ============="""
    from EasyTSAD.Evaluations.Protocols import EventF1PA, PointF1PA
    
    print("[LOG] å¼€å§‹è®¾ç½®è¯„ä¼°åè®®")
    gctrl.set_evals(
        [
            PointF1PA(),
            EventF1PA(),
            EventF1PA(mode="squeeze")
        ]
    )
    print("[LOG] è¯„ä¼°åè®®è®¾ç½®å®Œæˆ")

    print("[LOG] å¼€å§‹æ‰§è¡Œè¯„ä¼°")
    gctrl.do_evals(
        method=method,
        training_schema=training_schema
    )
    print("[LOG] è¯„ä¼°æ‰§è¡Œå®Œæˆ")
        
    """============= [PLOTTING SETTINGS] ============="""
    print("[LOG] å¼€å§‹ç»˜å›¾")
    gctrl.plots(
        method=method,
        training_schema=training_schema
    )
    print("[LOG] ç»˜å›¾å®Œæˆ")
    
    print("[LOG] VotingEnsembleæ‰§è¡Œå®Œæ¯•")
    print("=" * 80)
    print("ğŸ¯ VotingEnsembleè®¾è®¡ç†å¿µ:")
    print("   'å–é•¿è¡¥çŸ­ï¼ŒæŠ•ç¥¨å†³ç­–' - ç»Ÿè®¡å­¦çš„Pointç²¾åº¦ + æ·±åº¦å­¦ä¹ çš„Eventè¿ç»­æ€§")
    print("   ä¿æŒMTSExampleä¼˜åŠ¿: Point F1: 93%+")
    print("   æ·±åº¦å­¦ä¹ å¢å¼º: Event F1ç›®æ ‡: 80%+")
    print("   æ™ºèƒ½æŠ•ç¥¨: è‡ªé€‚åº”æƒé‡ï¼Œä»»åŠ¡å¯¼å‘èåˆ")
    print("=" * 80) 