import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from EasyTSAD.Controller import TSADController
from EasyTSAD.Methods import BaseMethod
from EasyTSAD.DataFactory import MTSData
from tqdm import tqdm

import warnings
warnings.filterwarnings("ignore")

# ============= æ•°æ®é›†ç±»å®šä¹‰ =============
class MTSDataset(torch.utils.data.Dataset):
    def __init__(self, tsData: MTSData, set_type: str, window: int, horize: int):
        assert set_type in ['train', 'test']
        self.set_type = set_type
        self.window = window
        self.horize = horize        
        
        if set_type == "train":
            rawdata = tsData.train
        elif set_type == "test":
            rawdata = tsData.test
        else:
            raise ValueError('Arg "set_type" in MTSDataset() must be one of "train", "test"')

        self.len, self.var_num = rawdata.shape
        self.sample_num = max(self.len - self.window - self.horize + 1, 0)
        self.samples, self.labels = self.__getsamples(rawdata)

    def __getsamples(self, data):
        X = torch.zeros((self.sample_num, self.window, self.var_num))
        Y = torch.zeros((self.sample_num, 1, self.var_num))

        for i in range(self.sample_num):
            start = i
            end = i + self.window
            X[i, :, :] = torch.from_numpy(data[start:end, :])
            Y[i, :, :] = torch.from_numpy(data[end+self.horize-1, :])

        return (X, Y)

    def __len__(self):
        return self.sample_num

    def __getitem__(self, idx):
        sample = [self.samples[idx, :, :], self.labels[idx, :, :]]
        return sample

# ============= ä¸“å®¶ç½‘ç»œç±»å®šä¹‰ =============
class Expert(nn.Module):
    def __init__(self, n_kernel, window, n_multiv, hidden_size, output_size, drop_out=0.2):
        super(Expert, self).__init__()
        self.conv = nn.Conv2d(1, n_kernel, (window, 1))
        self.dropout = nn.Dropout(drop_out)
        self.fc1 = nn.Linear(n_kernel * n_multiv, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)
        
    def forward(self, x):
        x = x.unsqueeze(dim=1).contiguous()
        x = F.relu(self.conv(x))
        x = self.dropout(x)
        
        out = torch.flatten(x, start_dim=1).contiguous()
        
        out = self.fc1(out)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)
        
        return out

# ============= å¡”ç½‘ç»œç±»å®šä¹‰ =============    
class Tower(nn.Module):
    def __init__(self, input_size, output_size, hidden_size=16, drop_out=0.1):
        super(Tower, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(drop_out)
        
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)
        
        return out

# ============= LightMMoEä¸»æ¨¡å‹ç±»å®šä¹‰ =============
class SimpleLightMMoEModel(nn.Module):
    def __init__(self, n_kernel, window, n_multiv, hidden_size, output_size, n_expert=4, 
                 sg_ratio=0.7, exp_dropout=0.2, tow_dropout=0.1, towers_hidden=16):
        super(SimpleLightMMoEModel, self).__init__()
        self.n_kernel = n_kernel
        self.window = window
        self.n_multiv = n_multiv
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.n_expert = n_expert
        self.sg_ratio = sg_ratio
        self.softmax = nn.Softmax(dim=1)

        # ä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList([
            Expert(n_kernel, window, n_multiv, hidden_size, output_size, exp_dropout)
            for _ in range(n_expert)
        ])
        
        # é—¨æ§ç½‘ç»œ
        self.w_gates = nn.ParameterList([
            nn.Parameter(torch.randn(window, n_expert), requires_grad=True)
            for _ in range(n_multiv)
        ])
        self.share_gate = nn.Parameter(torch.randn(window, n_expert), requires_grad=True)
        
        # å¡”ç½‘ç»œ
        self.towers = nn.ModuleList([
            Tower(output_size, 1, towers_hidden, tow_dropout)
            for _ in range(n_multiv)
        ])

    def forward(self, x):
        # ä¸“å®¶ç½‘ç»œè¾“å‡º
        experts_out = [e(x) for e in self.experts]
        experts_out_tensor = torch.stack(experts_out)
        
        # é—¨æ§ç½‘ç»œè¾“å‡º
        gates_out = [
            self.softmax((x[:,:,i] @ self.w_gates[i]) * (1 - self.sg_ratio) + (x[:,:,i] @ self.share_gate) * self.sg_ratio)
            for i in range(self.n_multiv)
        ]
        
        # é—¨æ§åŠ æƒä¸“å®¶è¾“å‡º
        tower_input = [
            g.t().unsqueeze(2).expand(-1, -1, self.output_size) * experts_out_tensor
            for g in gates_out
        ]
        tower_input = [torch.sum(ti, dim=0) for ti in tower_input]
        
        # å¡”ç½‘ç»œè¾“å‡º
        tower_output = [
            t(ti)
            for t, ti in zip(self.towers, tower_input)
        ]
        tower_output = torch.stack(tower_output, dim=0).permute(1,2,0)
        
        return tower_output

# ============= LightMMoEå¼‚å¸¸æ£€æµ‹æ–¹æ³•ç±» =============
class LightMMoE(BaseMethod):
    def __init__(self, params: dict) -> None:
        super().__init__()
        self.__anomaly_score = None
        self.model = None  # åˆå§‹åŒ–modelå±æ€§
        
        # LightMMoEè½»é‡åŒ–å‚æ•°é…ç½®
        self.config = {
            'seed': 2023,
            'n_multiv': 38,          # æ ¹æ®æ•°æ®è°ƒæ•´
            'horize': 1,
            'window': 16,            # å‡å°çª—å£å¤§å°æé«˜é€Ÿåº¦
            'batch_size': 64,        # æ‰¹é‡å¤§å°
            'epochs': 5,             # å‡å°‘è®­ç»ƒè½®æ•°

            'num_experts': 4,        # å‡å°‘ä¸“å®¶æ•°é‡
            'n_kernel': 8,           # å‡å°‘å·ç§¯æ ¸æ•°é‡
            'experts_out': 64,       # ä¸“å®¶è¾“å‡ºç»´åº¦
            'experts_hidden': 128,   # ä¸“å®¶éšè—å±‚ç»´åº¦
            'towers_hidden': 16,     # å¡”ç½‘ç»œéšè—å±‚ç»´åº¦
            'criterion': 'l2',       # æŸå¤±å‡½æ•°
            'exp_dropout': 0.2,      # ä¸“å®¶ç½‘ç»œdropout
            'tow_dropout': 0.1,      # å¡”ç½‘ç»œdropout
            'sg_ratio': 0.7,         # å…±äº«é—¨æ§æ¯”ä¾‹
            'lr': 0.001              # å­¦ä¹ ç‡
        }
        
        print(f"[LOG] LightMMoEåˆå§‹åŒ–å®Œæˆ")
        print(f"[LOG] è½»é‡åŒ–é…ç½®: {self.config['num_experts']}ä¸“å®¶, {self.config['n_kernel']}å·ç§¯æ ¸, {self.config['epochs']}è½®è®­ç»ƒ")

    def train_valid_phase(self, tsData: MTSData):
        print(f"\n[LOG] ========== LightMMoEè®­ç»ƒé˜¶æ®µå¼€å§‹ ==========")
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"[LOG] ä½¿ç”¨è®¾å¤‡: {device}")
        
        # ä½¿ç”¨configä¸­çš„å‚æ•°
        window_size = self.config['window']
        batch_size = self.config['batch_size']
        epochs = self.config['epochs']
        lr = self.config['lr']
        
        # ä»MTSDatasetè·å–æ•°æ®
        train_dataset = MTSDataset(tsData=tsData, set_type='train', window=window_size, horize=self.config['horize'])
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        
        # åŠ¨æ€è·å–æ•°æ®ç»´åº¦å¹¶æ›´æ–°config
        n_multiv = tsData.train.shape[1]
        self.config['n_multiv'] = n_multiv
        print(f"[LOG] æ•°æ®ç»´åº¦: {n_multiv}, è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}")
        
        # ä½¿ç”¨configä¸­çš„å‚æ•°åˆ›å»ºæ¨¡å‹
        self.model = SimpleLightMMoEModel(
            n_kernel=self.config['n_kernel'],
            window=window_size,
            n_multiv=n_multiv,
            hidden_size=self.config['experts_hidden'],
            output_size=self.config['experts_out'],
            n_expert=self.config['num_experts'],
            sg_ratio=self.config['sg_ratio'],
            exp_dropout=self.config['exp_dropout'],
            tow_dropout=self.config['tow_dropout'],
            towers_hidden=self.config['towers_hidden']
        ).to(device)
        
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
        criterion = nn.MSELoss()
        
        self.model.train()
        print(f"[LOG] å¼€å§‹è®­ç»ƒï¼Œå…± {epochs} ä¸ªepoch")
        print(f"[LOG] ä½¿ç”¨å‚æ•°: window={window_size}, batch_size={batch_size}, lr={lr}")
        print(f"[LOG] æ¨¡å‹å‚æ•°: experts={self.config['num_experts']}, kernel={self.config['n_kernel']}")
        
        # æ·»åŠ å¤–å±‚è¿›åº¦æ¡æ˜¾ç¤ºæ•´ä½“è®­ç»ƒè¿›åº¦
        epoch_bar = tqdm(range(epochs), desc="ğŸš€ LightMMoEè®­ç»ƒè¿›åº¦", ncols=100)
        
        for epoch in epoch_bar:
            total_loss = 0
            batch_count = 0
            
            # å†…å±‚è¿›åº¦æ¡æ˜¾ç¤ºå½“å‰epochçš„batchè¿›åº¦
            batch_bar = tqdm(train_loader, desc=f"ğŸ“Š Epoch {epoch+1}/{epochs}", leave=False, ncols=80)
            
            for batch_idx, (data, target) in enumerate(batch_bar):
                data, target = data.to(device), target.to(device)
                
                optimizer.zero_grad()
                output = self.model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                batch_count += 1
                
                # æ›´æ–°batchè¿›åº¦æ¡æ˜¾ç¤ºå½“å‰loss
                batch_bar.set_postfix({'loss': f'{loss.item():.6f}'})
            
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            
            # æ›´æ–°epochè¿›åº¦æ¡æ˜¾ç¤ºå¹³å‡loss
            epoch_bar.set_postfix({'avg_loss': f'{avg_loss:.6f}'})
            print(f"âœ… Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.6f}")
        
        epoch_bar.close()
        print(f"[LOG] ========== LightMMoEè®­ç»ƒé˜¶æ®µå®Œæˆ ==========\n")

    def test_phase(self, tsData: MTSData):
        print(f"\n[LOG] ========== LightMMoEæµ‹è¯•é˜¶æ®µå¼€å§‹ ==========")
        print(f"[LOG] æµ‹è¯•æ•°æ®å½¢çŠ¶: {tsData.test.shape}")
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ä½¿ç”¨configä¸­çš„å‚æ•°
        window_size = self.config['window']
        batch_size = self.config['batch_size']
        
        # ä½¿ç”¨MTSDatasetå¤„ç†æµ‹è¯•æ•°æ®
        test_dataset = MTSDataset(tsData=tsData, set_type='test', window=window_size, horize=self.config['horize'])
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        
        self.model.eval()
        anomaly_scores = []
        
        print(f"[LOG] å¼€å§‹æµ‹è¯•ï¼Œå…± {len(test_loader)} ä¸ªbatch")
        
        with torch.no_grad():
            for data, target in tqdm(test_loader, desc="ğŸ” LightMMoEæµ‹è¯•è¿›åº¦", ncols=80):
                data, target = data.to(device), target.to(device)
                
                output = self.model(data)
                mse = torch.mean((output - target) ** 2, dim=(1, 2))
                anomaly_scores.extend(mse.cpu().numpy())
        
        # è°ƒæ•´å¼‚å¸¸åˆ†æ•°é•¿åº¦ä»¥åŒ¹é…åŸå§‹æµ‹è¯•æ•°æ®
        full_scores = np.zeros(len(tsData.test))
        
        # å‰window_sizeä¸ªç‚¹ä½¿ç”¨0åˆ†æ•°
        full_scores[:window_size] = 0
        
        # ä»ç¬¬window_sizeä¸ªç‚¹å¼€å§‹ä½¿ç”¨å®é™…è®¡ç®—çš„åˆ†æ•°
        for i, score in enumerate(anomaly_scores):
            if i + window_size < len(full_scores):
                full_scores[i + window_size] = score
        
        self.__anomaly_score = full_scores
        print(f"[LOG] ========== LightMMoEæµ‹è¯•é˜¶æ®µå®Œæˆ ==========\n")

    def anomaly_score(self) -> np.ndarray:
        return self.__anomaly_score

    def param_statistic(self, save_file):
        if self.model is not None:
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            
            param_info = f"""
                LightMMoEè½»é‡çº§å¤šä¸“å®¶æ··åˆæ¨¡å‹å‚æ•°ç»Ÿè®¡:
                ==================================================
                æ€»å‚æ•°æ•°é‡: {total_params:,}
                å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}
                ä¸“å®¶æ•°é‡: {self.config['num_experts']}
                å·ç§¯æ ¸æ•°é‡: {self.config['n_kernel']}
                çª—å£å¤§å°: {self.config['window']}
                æ‰¹é‡å¤§å°: {self.config['batch_size']}
                è®­ç»ƒè½®æ•°: {self.config['epochs']}
                å­¦ä¹ ç‡: {self.config['lr']}
                ==================================================
                è½»é‡åŒ–è®¾è®¡ç†å¿µ: ç²¾ç®€æ¶æ„ï¼Œæå‡æ•ˆç‡ï¼Œä¿æŒæ€§èƒ½
                            """
        else:
            param_info = "LightMMoEæ¨¡å‹å°šæœªåˆå§‹åŒ–"
            
        with open(save_file, 'w', encoding='utf-8') as f:
            f.write(param_info)

# ============= ä¸»ç¨‹åºå…¥å£ =============
if __name__ == "__main__":
    print("ğŸ¯ ========== LightMMoEè½»é‡çº§å¤šä¸“å®¶æ··åˆå¼‚å¸¸æ£€æµ‹ ==========")
    print("[LOG] ç¨‹åºå¼€å§‹æ‰§è¡Œ")
    
    # Create a global controller
    gctrl = TSADController()
    print("[LOG] TSADControllerå·²åˆ›å»º")
    
    # Set dataset
    datasets = ["machine-1", "machine-2", "machine-3"]
    gctrl.set_dataset(
        dataset_type="MTS",
        dirname="./datasets",
        datasets=datasets,
    )
    print("[LOG] æ•°æ®é›†è®¾ç½®å®Œæˆ")

    print("[LOG] LightMMoEç±»å®šä¹‰å®Œæˆ")

    """============= Run LightMMoE algo. ============="""
    
    # some settings of this anomaly detection method
    method = "LightMMoE"  # string of your algo class

    print(f"[LOG] å¼€å§‹è¿è¡Œå®éªŒï¼Œmethod={method}")
    # run models
    gctrl.run_exps(
        method=method,
        training_schema="mts",
        hparams={
            "window": 16,
            "batch_size": 64,
            "epochs": 5,
            "lr": 0.001,
        },
        # use which method to preprocess original data. 
        preprocess="z-score",
    )
    print("[LOG] å®éªŒè¿è¡Œå®Œæˆ")
       
        
    """============= [EVALUATION SETTINGS] ============="""
    
    from EasyTSAD.Evaluations.Protocols import EventF1PA, PointF1PA
    # Specifying evaluation protocols
    print("[LOG] å¼€å§‹è®¾ç½®è¯„ä¼°åè®®")
    gctrl.set_evals(
        [
            PointF1PA(),
            EventF1PA(),
            EventF1PA(mode="squeeze")
        ]
    )
    print("[LOG] è¯„ä¼°åè®®è®¾ç½®å®Œæˆ")

    print("[LOG] å¼€å§‹æ‰§è¡Œè¯„ä¼°")
    gctrl.do_evals(
        method=method,
        training_schema="mts"
    )
    print("[LOG] è¯„ä¼°æ‰§è¡Œå®Œæˆ")
        
        
    """============= [PLOTTING SETTINGS] ============="""
    
    # plot anomaly scores for each curve
    print("[LOG] å¼€å§‹ç»˜å›¾")
    gctrl.plots(
        method=method,
        training_schema="mts"
    )
    print("[LOG] ç»˜å›¾å®Œæˆ")
    
    print("ğŸ‰ ========== LightMMoEæ‰§è¡Œå®Œæ¯• ==========")