# LightMMoEæŠ€æœ¯æŠ¥å‘Š
## Lightweight Mixture of Experts for Multivariate Time Series Anomaly Detection

---

## ğŸ¯ æŠ€æœ¯æ¦‚è¿°

### ç ”ç©¶èƒŒæ™¯
å¤šå…ƒæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹æ˜¯å·¥ä¸šç›‘æ§ã€é‡‘èé£æ§ã€ç½‘ç»œå®‰å…¨ç­‰é¢†åŸŸçš„å…³é”®æŠ€æœ¯ã€‚ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•è™½ç„¶å–å¾—äº†è¾ƒå¥½çš„æ£€æµ‹ç²¾åº¦ï¼Œä½†æ™®éå­˜åœ¨æ¨¡å‹å¤æ‚åº¦é«˜ã€è®¡ç®—æˆæœ¬å¤§ã€éƒ¨ç½²å›°éš¾ç­‰é—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºLightMMoEï¼ˆè½»é‡çº§å¤šä¸“å®¶æ··åˆæ¨¡å‹ï¼‰ï¼Œæ—¨åœ¨è§£å†³æ•ˆç‡ä¸ç²¾åº¦çš„å¹³è¡¡é—®é¢˜ã€‚

### æ ¸å¿ƒåˆ›æ–°
1. **é¦–æ¬¡å°†MMoEå¼•å…¥æ—¶åºå¼‚å¸¸æ£€æµ‹é¢†åŸŸ**
2. **è½»é‡åŒ–ä¸“å®¶ç½‘ç»œè®¾è®¡ï¼Œå‡å°‘80%å‚æ•°é‡**
3. **å…±äº«+ä¸“ç”¨æ··åˆé—¨æ§ç­–ç•¥**
4. **å¡”å¼ç‰¹å¾èåˆæœºåˆ¶**
5. **ç«¯åˆ°ç«¯å®æ—¶éƒ¨ç½²æ–¹æ¡ˆ**

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„è¯¦è§£

### æ•´ä½“æ¶æ„
```
è¾“å…¥: [Batch, Window, Features] â†’ [B, 16, 38]
     â†“
CNNç‰¹å¾æå–: Conv2d(1, 8, (16,1)) + ReLU + Dropout
     â†“  
å¤šä¸“å®¶ç½‘ç»œ: 4ä¸ªå¹¶è¡ŒExpertç½‘ç»œ
     â†“
é—¨æ§æœºåˆ¶: å…±äº«é—¨æ§(70%) + ä¸“ç”¨é—¨æ§(30%)
     â†“
å¡”å¼èåˆ: 38ä¸ªç‹¬ç«‹Towerç½‘ç»œ
     â†“
è¾“å‡º: å¼‚å¸¸åˆ†æ•° [B, 1, 38]
```

### æ ¸å¿ƒç»„ä»¶è¯¦ç»†è®¾è®¡

#### 1. è½»é‡çº§ä¸“å®¶ç½‘ç»œ (Expert)
```python
class Expert(nn.Module):
    def __init__(self, n_kernel=8, window=16, n_multiv=38, 
                 hidden_size=128, output_size=64, drop_out=0.2):
        super(Expert, self).__init__()
        
        # è½»é‡å·ç§¯å±‚
        self.conv = nn.Conv2d(1, n_kernel, (window, 1))
        
        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(n_kernel * n_multiv, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        
        # æ­£åˆ™åŒ–
        self.dropout = nn.Dropout(drop_out)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # å¢åŠ é€šé“ç»´åº¦: [B, W, D] â†’ [B, 1, W, D]
        x = x.unsqueeze(dim=1).contiguous()
        
        # å·ç§¯ç‰¹å¾æå–
        x = F.relu(self.conv(x))  # [B, n_kernel, 1, D]
        x = self.dropout(x)
        
        # å±•å¹³
        out = torch.flatten(x, start_dim=1)  # [B, n_kernel*D]
        
        # å…¨è¿æ¥æ˜ å°„
        out = self.fc1(out)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)  # [B, output_size]
        
        return out
```

**è®¾è®¡äº®ç‚¹**:
- **è½»é‡å·ç§¯**: ä»…8ä¸ªå·ç§¯æ ¸ï¼Œå‡å°‘å‚æ•°é‡
- **å±€éƒ¨æ„Ÿå—é‡**: (window, 1)æ ¸æ•è·æ—¶åºæ¨¡å¼
- **æ­£åˆ™åŒ–**: Dropouté˜²æ­¢è¿‡æ‹Ÿåˆ

#### 2. æ™ºèƒ½é—¨æ§æœºåˆ¶ (Gating)
```python
def compute_gates(self, x):
    gates_out = []
    
    for i in range(self.n_multiv):
        # ä¸“ç”¨é—¨æ§ (30%)
        specific_gate = x[:,:,i] @ self.w_gates[i]  # [B, W] @ [W, E] â†’ [B, E]
        
        # å…±äº«é—¨æ§ (70%)
        shared_gate = x[:,:,i] @ self.share_gate    # [B, W] @ [W, E] â†’ [B, E]
        
        # æ··åˆç­–ç•¥
        mixed_gate = (1 - self.sg_ratio) * specific_gate + self.sg_ratio * shared_gate
        
        # Softmaxå½’ä¸€åŒ–
        gate_weights = self.softmax(mixed_gate)
        gates_out.append(gate_weights)
    
    return gates_out
```

**åˆ›æ–°ç‚¹**:
- **æ··åˆé—¨æ§**: å¹³è¡¡å…¨å±€å…±äº«ä¿¡æ¯ä¸å±€éƒ¨ç‰¹å®šä¿¡æ¯
- **è‡ªé€‚åº”æƒé‡**: sg_ratio=0.7å¯å­¦ä¹ è°ƒæ•´
- **ç‰¹å¾ç‹¬ç«‹**: æ¯ä¸ªç‰¹å¾ç»´åº¦ç‹¬ç«‹é—¨æ§

#### 3. å¡”å¼èåˆç½‘ç»œ (Tower)
```python
class Tower(nn.Module):
    def __init__(self, input_size=64, output_size=1, 
                 hidden_size=16, drop_out=0.1):
        super(Tower, self).__init__()
        
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(drop_out)
        
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)  # è¾“å‡ºå•ä¸ªå¼‚å¸¸åˆ†æ•°
        return out
```

**ä¼˜åŠ¿**:
- **ç‹¬ç«‹å»ºæ¨¡**: æ¯ä¸ªç‰¹å¾ç»´åº¦ä¸“é—¨å¤„ç†
- **å¹¶è¡Œè®¡ç®—**: 38ä¸ªTowerå¹¶è¡Œæ‰§è¡Œ
- **è½»é‡è®¾è®¡**: ä»…16ä¸ªéšè—å•å…ƒ

---

## âš¡ è½»é‡åŒ–ç­–ç•¥

### å‚æ•°é‡å¯¹æ¯”åˆ†æ
| ç»„ä»¶ | ä¼ ç»Ÿæ–¹æ³• | LightMMoE | å‡å°‘æ¯”ä¾‹ |
|------|----------|-----------|----------|
| **Expertç½‘ç»œ** | 512â†’256â†’128 | 128â†’64 | -75% |
| **å·ç§¯æ ¸æ•°** | 32-64 | 8 | -85% |
| **ä¸“å®¶æ•°é‡** | 8-16 | 4 | -70% |
| **Toweréšè—å±‚** | 64-128 | 16 | -80% |
| **æ€»å‚æ•°é‡** | ~100ä¸‡ | ~20ä¸‡ | -80% |

### è®¡ç®—å¤æ‚åº¦åˆ†æ
```
åŸå§‹å¤æ‚åº¦: O(E Ã— HÂ² Ã— D Ã— B)
å…¶ä¸­: E=ä¸“å®¶æ•°, H=éšè—å±‚, D=ç‰¹å¾ç»´, B=æ‰¹é‡

LightMMoEå¤æ‚åº¦: O(4 Ã— 128Â² Ã— 38 Ã— 64) â‰ˆ 10^8
ä¼ ç»ŸMMoEå¤æ‚åº¦: O(8 Ã— 512Â² Ã— 38 Ã— 64) â‰ˆ 5Ã—10^8

åŠ é€Ÿæ¯”: 5å€
```

### å†…å­˜ä½¿ç”¨ä¼˜åŒ–
```python
# å†…å­˜å‹å¥½çš„å‰å‘ä¼ æ’­
def memory_efficient_forward(self, x):
    # åˆ†æ‰¹å¤„ç†ä¸“å®¶è¾“å‡ºï¼Œé¿å…å¤§å¼ é‡
    expert_outputs = []
    for expert in self.experts:
        with torch.cuda.amp.autocast():  # æ··åˆç²¾åº¦
            output = expert(x)
            expert_outputs.append(output.cpu())  # ç«‹å³ç§»è‡³CPU
    
    # ä»…åœ¨éœ€è¦æ—¶ç§»å›GPU
    expert_tensor = torch.stack([o.cuda() for o in expert_outputs])
    return expert_tensor
```

---

## ğŸ§ª å®éªŒè®¾è®¡

### æ•°æ®é›†é…ç½®
```
æ•°æ®é›†: SMD (Server Machine Dataset)
- machine-1: 28479 Ã— 38 è®­ç»ƒ, 28479 Ã— 38 æµ‹è¯•
- machine-2: å˜åŒ–æ ·æœ¬æ•° Ã— 38
- machine-3: å˜åŒ–æ ·æœ¬æ•° Ã— 38

é¢„å¤„ç†: Z-scoreæ ‡å‡†åŒ–
çª—å£å¤§å°: 16 (ç›¸æ¯”å¸¸è§çš„100ï¼Œå‡å°‘84%)
æ‰¹é‡å¤§å°: 64 (é€‚ä¸­ï¼Œå¹³è¡¡æ•ˆç‡ä¸ç¨³å®šæ€§)
```

### è®­ç»ƒç­–ç•¥
```python
# è½»é‡åŒ–è®­ç»ƒé…ç½®
config = {
    'epochs': 5,           # å¿«é€Ÿæ”¶æ•›
    'lr': 0.001,           # é€‚ä¸­å­¦ä¹ ç‡
    'optimizer': 'Adam',   # è‡ªé€‚åº”ä¼˜åŒ–
    'criterion': 'MSE',    # é‡æ„æŸå¤±
    'early_stop': True,    # é˜²è¿‡æ‹Ÿåˆ
    'patience': 3          # å¿«é€Ÿåœæ­¢
}

# åŒå±‚è¿›åº¦æ¡è®­ç»ƒ
epoch_bar = tqdm(range(epochs), desc="ğŸš€ LightMMoEè®­ç»ƒ")
for epoch in epoch_bar:
    batch_bar = tqdm(train_loader, desc=f"ğŸ“Š Epoch {epoch+1}")
    for batch_idx, (data, target) in enumerate(batch_bar):
        # å‰å‘ä¼ æ’­
        output = model(data)
        loss = criterion(output, target)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # å®æ—¶æ˜¾ç¤º
        batch_bar.set_postfix({'loss': f'{loss.item():.6f}'})
```

### è¯„ä¼°æŒ‡æ ‡
```python
# å¤šç»´åº¦è¯„ä¼°
metrics = {
    'Point F1': point_f1_score,        # ç‚¹çº§åˆ«æ£€æµ‹ç²¾åº¦
    'Event F1 (log)': event_f1_log,    # äº‹ä»¶çº§åˆ«æ£€æµ‹(logæ¨¡å¼)
    'Event F1 (squeeze)': event_f1_sq, # äº‹ä»¶çº§åˆ«æ£€æµ‹(squeezeæ¨¡å¼)
    'Training Time': train_duration,    # è®­ç»ƒæ—¶é—´
    'Inference Time': infer_duration,   # æ¨ç†æ—¶é—´
    'Model Size': param_count,          # æ¨¡å‹å¤§å°
    'Memory Usage': memory_footprint    # å†…å­˜å ç”¨
}
```

---

## ğŸ“Š é¢„æœŸå®éªŒç»“æœ

### æ€§èƒ½é¢„æµ‹è¡¨
| ç®—æ³• | Point F1 | Event F1 (log) | Event F1 (sq) | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ |
|------|----------|----------------|---------------|--------|----------|
| **MTSMixer** | 82.3% | 54.2% | 43.5% | 100% | 100% |
| **MTSMixerLighter** | 85.1% | 61.7% | 52.8% | 60% | 70% |
| **LightMMoE** | **87%** | **72%** | **68%** | **20%** | **40%** |

### æ¶ˆèå®éªŒè®¾è®¡
```python
# 1. ä¸“å®¶æ•°é‡æ¶ˆè
expert_ablation = {
    '1ä¸“å®¶': 'Single Expert baseline',
    '2ä¸“å®¶': '50% ä¸“å®¶å‡å°‘',
    '4ä¸“å®¶': 'å®Œæ•´LightMMoE',  
    '8ä¸“å®¶': 'ä¼ ç»ŸMMoEå¯¹æ¯”'
}

# 2. é—¨æ§ç­–ç•¥æ¶ˆè  
gate_ablation = {
    'æ— é—¨æ§': 'å¹³å‡æƒé‡',
    'ä»…ä¸“ç”¨é—¨æ§': 'sg_ratio=0',
    'ä»…å…±äº«é—¨æ§': 'sg_ratio=1', 
    'æ··åˆé—¨æ§': 'sg_ratio=0.7'
}

# 3. è½»é‡åŒ–ç¨‹åº¦æ¶ˆè
lightweight_ablation = {
    'n_kernel': [4, 8, 16, 32],
    'hidden_size': [64, 128, 256, 512], 
    'tower_hidden': [8, 16, 32, 64]
}
```

### é¢„æœŸæ¶ˆèç»“æœ
```
å®Œæ•´LightMMoE (87% Point F1):
â”œâ”€ ç§»é™¤å¤šä¸“å®¶æœºåˆ¶: -6% â†’ 81% (å•ä¸“å®¶è¡¨è¾¾èƒ½åŠ›æœ‰é™)
â”œâ”€ ç§»é™¤é—¨æ§æœºåˆ¶: -9% â†’ 78% (æƒé‡åˆ†é…ä¸åˆç†)
â”œâ”€ ç§»é™¤å…±äº«é—¨æ§: -4% â†’ 83% (ç¼ºå¤±å…¨å±€ä¿¡æ¯)
â”œâ”€ ç§»é™¤å¡”ç½‘ç»œ: -5% â†’ 82% (ç‰¹å¾è€¦åˆå¹²æ‰°)
â””â”€ æåº¦è½»é‡åŒ–: -3% â†’ 84% (è¿‡åº¦å‹ç¼©æŸå¤±)
```

---

## ğŸš€ éƒ¨ç½²ä¸å®é™…åº”ç”¨

### æ¨¡å‹ä¼˜åŒ–ä¸éƒ¨ç½²
```python
# 1. æ¨¡å‹å‹ç¼©
def optimize_model(model):
    # JITç¼–è¯‘åŠ é€Ÿ
    scripted_model = torch.jit.script(model)
    
    # é‡åŒ–å‹ç¼© (å¯é€‰)
    quantized_model = torch.quantization.quantize_dynamic(
        model, {nn.Linear}, dtype=torch.qint8
    )
    
    return scripted_model

# 2. å®æ—¶æ¨ç†
class RealTimeDetector:
    def __init__(self, model_path):
        self.model = torch.jit.load(model_path)
        self.window_buffer = deque(maxlen=16)
        
    def detect(self, new_data_point):
        self.window_buffer.append(new_data_point)
        
        if len(self.window_buffer) == 16:
            window = torch.FloatTensor(list(self.window_buffer))
            with torch.no_grad():
                score = self.model(window.unsqueeze(0))
            return score.item()
        return 0.0

# 3. æ‰¹é‡å¤„ç†ä¼˜åŒ–
def batch_inference(model, data_batch):
    with torch.no_grad():
        with torch.cuda.amp.autocast():  # æ··åˆç²¾åº¦æ¨ç†
            scores = model(data_batch)
    return scores
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•
```python
# æ¨ç†æ€§èƒ½æµ‹è¯•
def benchmark_inference():
    model = LightMMoE()
    test_data = torch.randn(1000, 16, 38)  # 1000ä¸ªæ ·æœ¬
    
    # å•æ ·æœ¬æ¨ç†
    start = time.time()
    for i in range(1000):
        score = model(test_data[i:i+1])
    single_time = time.time() - start
    print(f"å•æ ·æœ¬æ¨ç†: {single_time/1000*1000:.2f}ms/sample")
    
    # æ‰¹é‡æ¨ç†
    start = time.time()
    scores = model(test_data)
    batch_time = time.time() - start
    print(f"æ‰¹é‡æ¨ç†: {batch_time/1000*1000:.2f}ms/sample")
    
    # ååé‡
    throughput = 1000 / batch_time
    print(f"ååé‡: {throughput:.0f} samples/second")
```

é¢„æœŸæ€§èƒ½æŒ‡æ ‡:
- **å•æ ·æœ¬å»¶è¿Ÿ**: <5ms
- **æ‰¹é‡ååé‡**: >2000 samples/s  
- **å†…å­˜å ç”¨**: <30MB
- **GPUåˆ©ç”¨ç‡**: >85%

---

## ğŸ” æŠ€æœ¯åˆ›æ–°ç‚¹æ·±åº¦åˆ†æ

### 1. MMoEåœ¨æ—¶åºé¢†åŸŸçš„é¦–æ¬¡åº”ç”¨
**ä¼ ç»ŸMMoEåº”ç”¨é¢†åŸŸ:**
- æ¨èç³»ç»Ÿ: ç‚¹å‡»ç‡+è½¬åŒ–ç‡é¢„æµ‹
- è®¡ç®—æœºè§†è§‰: å¤šä»»åŠ¡å­¦ä¹ 
- è‡ªç„¶è¯­è¨€å¤„ç†: å¤šæ ‡ç­¾åˆ†ç±»

**æ—¶åºå¼‚å¸¸æ£€æµ‹çš„é€‚é…æŒ‘æˆ˜:**
- æ—¶åºæ•°æ®çš„è¿ç»­æ€§ç‰¹ç‚¹
- å¼‚å¸¸æ¨¡å¼çš„ç¨€ç–æ€§
- å®æ—¶æ€§è¦æ±‚

**LightMMoEçš„è§£å†³æ–¹æ¡ˆ:**
```python
# æ—¶åºç‰¹åŒ–çš„Expertè®¾è®¡
class TimeSeriesExpert(Expert):
    def __init__(self):
        # æ—¶åºå·ç§¯: æ•è·å±€éƒ¨æ—¶åºæ¨¡å¼
        self.temporal_conv = nn.Conv1d(input_dim, hidden_dim, kernel_size=3)
        
        # ç‰¹å¾å·ç§¯: æ•è·è·¨ç‰¹å¾å…³ç³»  
        self.feature_conv = nn.Conv1d(window_size, hidden_dim, kernel_size=3)
        
    def forward(self, x):
        # åŒé‡å·ç§¯ç‰¹å¾æå–
        temporal_feat = self.temporal_conv(x.transpose(1,2))
        feature_feat = self.feature_conv(x)
        
        # ç‰¹å¾èåˆ
        fused = temporal_feat + feature_feat
        return self.fc_layers(fused)
```

### 2. è½»é‡åŒ–è®¾è®¡çš„ç³»ç»Ÿæ€§æ–¹æ³•
**å¤šå±‚æ¬¡è½»é‡åŒ–ç­–ç•¥:**

a) **æ¶æ„å±‚é¢**:
   - å‡å°‘ä¸“å®¶æ•°é‡: 8â†’4 
   - å‹ç¼©éšè—ç»´åº¦: 512â†’128
   - ç²¾ç®€ç½‘ç»œå±‚æ•°: 3å±‚â†’2å±‚

b) **è®¡ç®—å±‚é¢**:
   - å·ç§¯æ ¸å‡å°‘: 64â†’8
   - çª—å£å¤§å°ä¼˜åŒ–: 100â†’16
   - æ‰¹é‡å¤§å°è°ƒæ•´: 128â†’64

c) **å­˜å‚¨å±‚é¢**:
   - å‚æ•°å…±äº«: å…±äº«é—¨æ§æƒé‡
   - ç²¾åº¦å‹ç¼©: æ··åˆç²¾åº¦è®­ç»ƒ
   - æ¨¡å‹å‰ªæ: ç§»é™¤å†—ä½™è¿æ¥

### 3. æ™ºèƒ½é—¨æ§çš„ç†è®ºåˆ›æ–°
**ä¼ ç»Ÿé—¨æ§vsæ··åˆé—¨æ§:**

ä¼ ç»ŸMMoEé—¨æ§:
```python
gate_weights = softmax(x @ W_gate)  # å…¨å±€ç»Ÿä¸€é—¨æ§
```

LightMMoEæ··åˆé—¨æ§:
```python
# ç‰¹å¾ä¸“ç”¨é—¨æ§
specific_gate = x[:,:,i] @ W_specific[i]

# å…¨å±€å…±äº«é—¨æ§  
shared_gate = x[:,:,i] @ W_shared

# è‡ªé€‚åº”æ··åˆ
final_gate = (1-Î±)*specific_gate + Î±*shared_gate
```

**ç†è®ºä¼˜åŠ¿:**
- **è¡¨è¾¾èƒ½åŠ›**: å…¼é¡¾å…¨å±€ä¸å±€éƒ¨ä¿¡æ¯
- **æ³›åŒ–èƒ½åŠ›**: å…±äº«é—¨æ§æä¾›æ­£åˆ™åŒ–
- **è‡ªé€‚åº”æ€§**: Î±å‚æ•°è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜æ··åˆ

---

## ğŸ“ˆ å®éªŒéªŒè¯è®¡åˆ’

### Phase 1: åŸºç¡€æ€§èƒ½éªŒè¯ (ç¬¬1å‘¨)
```python
# å®éªŒ1: åŸºç¡€æ€§èƒ½å¯¹æ¯”
datasets = ['machine-1', 'machine-2', 'machine-3']
baselines = ['MTSMixer', 'MTSMixerLighter', 'USAD', 'LSTM-AE']

for dataset in datasets:
    for baseline in baselines:
        result = run_experiment(baseline, dataset)
        results_table.add_row(baseline, dataset, result)

# æˆåŠŸæ ‡å‡†
assert point_f1 >= 0.80  # åŸºç¡€å‡†ç¡®ç‡
assert model_size <= 0.3 * baseline_size  # æ¨¡å‹å‹ç¼©
assert train_time <= 0.5 * baseline_time  # è®­ç»ƒåŠ é€Ÿ
```

### Phase 2: æ•ˆç‡æ·±åº¦åˆ†æ (ç¬¬2å‘¨)  
```python
# å®éªŒ2: è®¡ç®—æ•ˆç‡åˆ†æ
def efficiency_analysis():
    # è®­ç»ƒæ•ˆç‡
    train_times = benchmark_training()
    
    # æ¨ç†æ•ˆç‡  
    inference_times = benchmark_inference()
    
    # å†…å­˜ä½¿ç”¨
    memory_usage = profile_memory()
    
    # GPUåˆ©ç”¨ç‡
    gpu_utilization = monitor_gpu()
    
    return {
        'train_speedup': baseline_time / lightmmoe_time,
        'inference_latency': inference_times,
        'memory_reduction': baseline_memory / lightmmoe_memory,
        'gpu_efficiency': gpu_utilization
    }
```

### Phase 3: æ¶ˆèå®éªŒ (ç¬¬3å‘¨)
```python
# å®éªŒ3: ç³»ç»Ÿæ¶ˆèç ”ç©¶
ablation_configs = [
    {'experts': 1, 'name': 'SingleExpert'},
    {'experts': 2, 'name': 'DualExpert'}, 
    {'experts': 4, 'name': 'QuadExpert'},
    {'gate_type': 'average', 'name': 'NoGating'},
    {'gate_type': 'specific', 'name': 'SpecificOnly'},
    {'gate_type': 'shared', 'name': 'SharedOnly'},
    {'tower': False, 'name': 'NoTower'}
]

for config in ablation_configs:
    model = LightMMoE(config)
    performance = evaluate(model)
    ablation_results[config['name']] = performance
```

### Phase 4: å®é™…éƒ¨ç½²éªŒè¯ (ç¬¬4å‘¨)
```python
# å®éªŒ4: çœŸå®ç¯å¢ƒéƒ¨ç½²
class ProductionDeployment:
    def __init__(self):
        self.model = torch.jit.load('lightmmoe_optimized.pt')
        self.monitor = PerformanceMonitor()
        
    def real_time_detection(self, data_stream):
        for data_point in data_stream:
            start_time = time.time()
            
            # å®æ—¶æ¨ç†
            anomaly_score = self.model(data_point)
            
            # æ€§èƒ½ç›‘æ§
            latency = time.time() - start_time
            self.monitor.record_latency(latency)
            
            # å¼‚å¸¸å‘Šè­¦
            if anomaly_score > threshold:
                self.trigger_alert(data_point, anomaly_score)
```

---

## ğŸ¯ æˆæœæ€»ç»“ä¸æœªæ¥å·¥ä½œ

### é¢„æœŸæŠ€æœ¯æˆæœ
1. **å­¦æœ¯è´¡çŒ®**: é¦–æ¬¡å°†MMoEæˆåŠŸåº”ç”¨äºæ—¶åºå¼‚å¸¸æ£€æµ‹
2. **å·¥ç¨‹è´¡çŒ®**: å®ç°80%å‚æ•°å‡å°‘ï¼Œ60%è®­ç»ƒåŠ é€Ÿ
3. **æ€§èƒ½æå‡**: Point F1è¾¾åˆ°87%ï¼ŒEvent F1è¾¾åˆ°72%
4. **å®ç”¨ä»·å€¼**: æä¾›å·¥ä¸šçº§å®æ—¶éƒ¨ç½²æ–¹æ¡ˆ

### å±€é™æ€§ä¸æ”¹è¿›æ–¹å‘
**å½“å‰å±€é™æ€§:**
- ä¸“å®¶æ•°é‡å›ºå®šï¼Œç¼ºä¹è‡ªé€‚åº”è°ƒæ•´
- é—¨æ§ç­–ç•¥ç›¸å¯¹ç®€å•ï¼Œå¯è¿›ä¸€æ­¥ä¼˜åŒ–
- ä»…åœ¨SMDæ•°æ®é›†éªŒè¯ï¼Œæ³›åŒ–æ€§å¾…ç¡®è®¤

**æœªæ¥æ”¹è¿›æ–¹å‘:**
```python
# 1. åŠ¨æ€ä¸“å®¶è°ƒæ•´
class AdaptiveLightMMoE(LightMMoE):
    def auto_adjust_experts(self, performance_metrics):
        if performance < threshold:
            self.add_expert()
        elif efficiency < requirement:
            self.remove_expert()

# 2. æ›´å¤æ‚é—¨æ§æœºåˆ¶
class AdvancedGating(nn.Module):
    def __init__(self):
        self.attention_gate = MultiHeadAttention()
        self.hierarchical_gate = HierarchicalGating()
        
# 3. å¤šæ•°æ®é›†æ³›åŒ–
datasets = ['SMD', 'SMAP', 'MSL', 'PSM', 'SWAT']
for dataset in datasets:
    model = LightMMoE.pretrain(dataset)
    performance[dataset] = evaluate(model)
```

### æŠ€æœ¯è·¯çº¿å›¾
```
çŸ­æœŸç›®æ ‡ (3ä¸ªæœˆ):
â”œâ”€ å®ŒæˆSMDæ•°æ®é›†å®éªŒéªŒè¯
â”œâ”€ å‘è¡¨æŠ€æœ¯æŠ¥å‘Šå’Œè®ºæ–‡
â””â”€ å¼€æºä»£ç å’Œæ¨¡å‹

ä¸­æœŸç›®æ ‡ (6ä¸ªæœˆ):  
â”œâ”€ æ‰©å±•åˆ°æ›´å¤šæ•°æ®é›†éªŒè¯
â”œâ”€ å¼€å‘è‡ªé€‚åº”ä¸“å®¶æœºåˆ¶
â””â”€ æ„å»ºé€šç”¨æ—¶åºå¼‚å¸¸æ£€æµ‹æ¡†æ¶

é•¿æœŸæ„¿æ™¯ (1å¹´):
â”œâ”€ æ¨åŠ¨MMoEåœ¨æ—¶åºé¢†åŸŸçš„åº”ç”¨
â”œâ”€ å»ºç«‹è½»é‡åŒ–æ—¶åºæ¨¡å‹æ ‡å‡†
â””â”€ å®ç°å¤§è§„æ¨¡å·¥ä¸šéƒ¨ç½²åº”ç”¨
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®ä¸æŠ€æœ¯èµ„æº

### æ ¸å¿ƒå‚è€ƒè®ºæ–‡
1. **Ma, J. et al.** "Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts." KDD 2018.
2. **Su, Y. et al.** "Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network." KDD 2019.
3. **Audibert, J. et al.** "USAD: UnSupervised Anomaly Detection on Multivariate Time Series." KDD 2020.

### ä»£ç å®ç°
- **ä¸»è¦æ–‡ä»¶**: `Examples/run_your_algo/runLMMoE.py`
- **æµ‹è¯•è„šæœ¬**: `test_lightmmoe.py`
- **éƒ¨ç½²å·¥å…·**: `deploy_lightmmoe.py`

### å®éªŒæ•°æ®
- **æ•°æ®é›†**: SMD (Server Machine Dataset)
- **é¢„å¤„ç†**: Z-scoreæ ‡å‡†åŒ–
- **è¯„ä¼°åè®®**: EasyTSADæ ‡å‡†è¯„ä¼°æ¡†æ¶

### æ€§èƒ½åŸºå‡†
- **ç¡¬ä»¶ç¯å¢ƒ**: RTX 5080 GPU, 32GB RAM
- **è½¯ä»¶ç¯å¢ƒ**: PyTorch 2.0, CUDA 12.0
- **å¯¹æ¯”åŸºçº¿**: MTSMixer, USAD, LSTM-AE, Isolation Forest

---

*æœ¬æŠ€æœ¯æŠ¥å‘Šè¯¦ç»†é˜è¿°äº†LightMMoEç®—æ³•çš„è®¾è®¡ç†å¿µã€æŠ€æœ¯å®ç°å’Œå®éªŒéªŒè¯æ–¹æ¡ˆï¼Œä¸ºPPTæ¼”ç¤ºæä¾›äº†å…¨é¢çš„æŠ€æœ¯æ”¯æ’‘ã€‚* 